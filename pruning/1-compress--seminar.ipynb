{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Прореживание нейронных сетей\n",
    "\n",
    "В этой лабораторной мы попробуем уменьшить размер нейронной сети за счет удаления из нее части весов. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f2192342498>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED=9876\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве данных будем использовать стандартный mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0       0       0       0       0       0       0       0       0       0   \n",
       "1       0       0       0       0       0       0       0       0       0   \n",
       "2       0       0       0       0       0       0       0       0       0   \n",
       "3       0       0       0       0       0       0       0       0       0   \n",
       "4       0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel10  ...    pixel776  pixel777  pixel778  pixel779  pixel780  pixel781  \\\n",
       "0        0  ...           0         0         0         0         0         0   \n",
       "1        0  ...           0         0         0         0         0         0   \n",
       "2        0  ...           0         0         0         0         0         0   \n",
       "3        0  ...           0         0         0         0         0         0   \n",
       "4        0  ...           0         0         0         0         0         0   \n",
       "\n",
       "   pixel782  pixel783  pixel784  class  \n",
       "0         0         0         0      5  \n",
       "1         0         0         0      0  \n",
       "2         0         0         0      4  \n",
       "3         0         0         0      1  \n",
       "4         0         0         0      9  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/data/mnist_784.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "y = df['class'].values\n",
    "X = df.drop(['class'],axis=1).values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f21379be1d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[0].reshape(28, 28))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первое, что мы попробуем сделать - это собрать какую-то несложную архитектуру нейронной сети и просто обучить ее на данных. \n",
    "\n",
    "После этого мы замерим ее размер, а также качество, которое она выдает. Все дальнейшие полученные модели будем сравнивать с этими результатами, как с базовыми и понимать - получилось лучше или хуже.\n",
    "\n",
    "Вначале просто подготовим данные для обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "torch_X_train = torch.from_numpy(X_train).type(torch.LongTensor)\n",
    "torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "torch_X_test = torch.from_numpy(X_test).type(torch.LongTensor)\n",
    "torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "\n",
    "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В реальной жизни для задачи распознавания числа на картинке мы бы скорее всего использовали более продвинутую архитектуру сети, однако для наглядности мы возьмем простую сеть, которая при этом имеет много параметров. В ней будут просто три полносвязных слоя: 784 - 250 - 100 - 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear1): Linear(in_features=784, out_features=250, bias=True)\n",
      "  (linear2): Linear(in_features=250, out_features=100, bias=True)\n",
      "  (linear3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(784,250)\n",
    "        self.linear2 = nn.Linear(250,100)\n",
    "        self.linear3 = nn.Linear(100,10)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = self.linear3(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "\n",
    "mlp = MLP()\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем самым обычным способом, используя кросс-энтропию в качестве меры ошибки и используя 5 эпох"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def fit(model, train_loader, epoch_number=5):\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    for epoch in range(epoch_number):\n",
    "        correct = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            var_X_batch = Variable(X_batch).float()\n",
    "            var_y_batch = Variable(y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(var_X_batch)\n",
    "            loss = error(output, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicted = torch.max(output.data, 1)[1] \n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            if batch_idx % 50 == 0:\n",
    "                print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                    epoch, batch_idx*len(X_batch), len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.data, float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/49000 (0%)]\tLoss: 8.752556\t Accuracy:9.375%\n",
      "Epoch : 0 [1600/49000 (3%)]\tLoss: 0.328136\t Accuracy:69.179%\n",
      "Epoch : 0 [3200/49000 (7%)]\tLoss: 0.348056\t Accuracy:76.825%\n",
      "Epoch : 0 [4800/49000 (10%)]\tLoss: 0.260351\t Accuracy:79.988%\n",
      "Epoch : 0 [6400/49000 (13%)]\tLoss: 0.274883\t Accuracy:82.478%\n",
      "Epoch : 0 [8000/49000 (16%)]\tLoss: 0.284315\t Accuracy:83.877%\n",
      "Epoch : 0 [9600/49000 (20%)]\tLoss: 0.142769\t Accuracy:84.759%\n",
      "Epoch : 0 [11200/49000 (23%)]\tLoss: 0.533784\t Accuracy:85.684%\n",
      "Epoch : 0 [12800/49000 (26%)]\tLoss: 0.383286\t Accuracy:86.386%\n",
      "Epoch : 0 [14400/49000 (29%)]\tLoss: 0.217748\t Accuracy:86.973%\n",
      "Epoch : 0 [16000/49000 (33%)]\tLoss: 0.247283\t Accuracy:87.512%\n",
      "Epoch : 0 [17600/49000 (36%)]\tLoss: 0.306317\t Accuracy:87.891%\n",
      "Epoch : 0 [19200/49000 (39%)]\tLoss: 0.753405\t Accuracy:88.176%\n",
      "Epoch : 0 [20800/49000 (42%)]\tLoss: 0.040594\t Accuracy:88.599%\n",
      "Epoch : 0 [22400/49000 (46%)]\tLoss: 0.437389\t Accuracy:88.820%\n",
      "Epoch : 0 [24000/49000 (49%)]\tLoss: 0.134156\t Accuracy:89.073%\n",
      "Epoch : 0 [25600/49000 (52%)]\tLoss: 0.217135\t Accuracy:89.263%\n",
      "Epoch : 0 [27200/49000 (55%)]\tLoss: 0.716109\t Accuracy:89.450%\n",
      "Epoch : 0 [28800/49000 (59%)]\tLoss: 0.096313\t Accuracy:89.695%\n",
      "Epoch : 0 [30400/49000 (62%)]\tLoss: 0.448626\t Accuracy:89.876%\n",
      "Epoch : 0 [32000/49000 (65%)]\tLoss: 0.055153\t Accuracy:90.085%\n",
      "Epoch : 0 [33600/49000 (69%)]\tLoss: 0.471944\t Accuracy:90.197%\n",
      "Epoch : 0 [35200/49000 (72%)]\tLoss: 0.126615\t Accuracy:90.296%\n",
      "Epoch : 0 [36800/49000 (75%)]\tLoss: 0.249904\t Accuracy:90.465%\n",
      "Epoch : 0 [38400/49000 (78%)]\tLoss: 0.182081\t Accuracy:90.591%\n",
      "Epoch : 0 [40000/49000 (82%)]\tLoss: 0.088863\t Accuracy:90.690%\n",
      "Epoch : 0 [41600/49000 (85%)]\tLoss: 0.157750\t Accuracy:90.860%\n",
      "Epoch : 0 [43200/49000 (88%)]\tLoss: 0.304473\t Accuracy:90.977%\n",
      "Epoch : 0 [44800/49000 (91%)]\tLoss: 0.286080\t Accuracy:91.120%\n",
      "Epoch : 0 [46400/49000 (95%)]\tLoss: 0.173301\t Accuracy:91.271%\n",
      "Epoch : 0 [48000/49000 (98%)]\tLoss: 0.242835\t Accuracy:91.333%\n",
      "Epoch : 1 [0/49000 (0%)]\tLoss: 0.230641\t Accuracy:93.750%\n",
      "Epoch : 1 [1600/49000 (3%)]\tLoss: 0.084594\t Accuracy:95.282%\n",
      "Epoch : 1 [3200/49000 (7%)]\tLoss: 0.120789\t Accuracy:95.111%\n",
      "Epoch : 1 [4800/49000 (10%)]\tLoss: 0.324764\t Accuracy:95.281%\n",
      "Epoch : 1 [6400/49000 (13%)]\tLoss: 0.046762\t Accuracy:95.274%\n",
      "Epoch : 1 [8000/49000 (16%)]\tLoss: 0.377936\t Accuracy:95.169%\n",
      "Epoch : 1 [9600/49000 (20%)]\tLoss: 0.040517\t Accuracy:95.152%\n",
      "Epoch : 1 [11200/49000 (23%)]\tLoss: 0.271299\t Accuracy:95.175%\n",
      "Epoch : 1 [12800/49000 (26%)]\tLoss: 0.196139\t Accuracy:95.192%\n",
      "Epoch : 1 [14400/49000 (29%)]\tLoss: 0.296196\t Accuracy:95.226%\n",
      "Epoch : 1 [16000/49000 (33%)]\tLoss: 0.072983\t Accuracy:95.291%\n",
      "Epoch : 1 [17600/49000 (36%)]\tLoss: 0.115043\t Accuracy:95.372%\n",
      "Epoch : 1 [19200/49000 (39%)]\tLoss: 0.454547\t Accuracy:95.300%\n",
      "Epoch : 1 [20800/49000 (42%)]\tLoss: 0.023817\t Accuracy:95.320%\n",
      "Epoch : 1 [22400/49000 (46%)]\tLoss: 0.048616\t Accuracy:95.266%\n",
      "Epoch : 1 [24000/49000 (49%)]\tLoss: 0.057141\t Accuracy:95.281%\n",
      "Epoch : 1 [25600/49000 (52%)]\tLoss: 0.162487\t Accuracy:95.244%\n",
      "Epoch : 1 [27200/49000 (55%)]\tLoss: 0.346706\t Accuracy:95.270%\n",
      "Epoch : 1 [28800/49000 (59%)]\tLoss: 0.083044\t Accuracy:95.311%\n",
      "Epoch : 1 [30400/49000 (62%)]\tLoss: 0.110950\t Accuracy:95.301%\n",
      "Epoch : 1 [32000/49000 (65%)]\tLoss: 0.089075\t Accuracy:95.342%\n",
      "Epoch : 1 [33600/49000 (69%)]\tLoss: 0.284222\t Accuracy:95.362%\n",
      "Epoch : 1 [35200/49000 (72%)]\tLoss: 0.151876\t Accuracy:95.382%\n",
      "Epoch : 1 [36800/49000 (75%)]\tLoss: 0.038307\t Accuracy:95.436%\n",
      "Epoch : 1 [38400/49000 (78%)]\tLoss: 0.052031\t Accuracy:95.447%\n",
      "Epoch : 1 [40000/49000 (82%)]\tLoss: 0.053218\t Accuracy:95.461%\n",
      "Epoch : 1 [41600/49000 (85%)]\tLoss: 0.054021\t Accuracy:95.506%\n",
      "Epoch : 1 [43200/49000 (88%)]\tLoss: 0.103841\t Accuracy:95.536%\n",
      "Epoch : 1 [44800/49000 (91%)]\tLoss: 0.275637\t Accuracy:95.548%\n",
      "Epoch : 1 [46400/49000 (95%)]\tLoss: 0.035474\t Accuracy:95.574%\n",
      "Epoch : 1 [48000/49000 (98%)]\tLoss: 0.008486\t Accuracy:95.578%\n",
      "Epoch : 2 [0/49000 (0%)]\tLoss: 0.206194\t Accuracy:93.750%\n",
      "Epoch : 2 [1600/49000 (3%)]\tLoss: 0.042208\t Accuracy:96.446%\n",
      "Epoch : 2 [3200/49000 (7%)]\tLoss: 0.069781\t Accuracy:96.473%\n",
      "Epoch : 2 [4800/49000 (10%)]\tLoss: 0.257454\t Accuracy:96.233%\n",
      "Epoch : 2 [6400/49000 (13%)]\tLoss: 0.084607\t Accuracy:96.331%\n",
      "Epoch : 2 [8000/49000 (16%)]\tLoss: 0.109836\t Accuracy:96.277%\n",
      "Epoch : 2 [9600/49000 (20%)]\tLoss: 0.090007\t Accuracy:96.065%\n",
      "Epoch : 2 [11200/49000 (23%)]\tLoss: 0.306766\t Accuracy:96.056%\n",
      "Epoch : 2 [12800/49000 (26%)]\tLoss: 0.099508\t Accuracy:96.026%\n",
      "Epoch : 2 [14400/49000 (29%)]\tLoss: 0.204413\t Accuracy:96.113%\n",
      "Epoch : 2 [16000/49000 (33%)]\tLoss: 0.046121\t Accuracy:96.158%\n",
      "Epoch : 2 [17600/49000 (36%)]\tLoss: 0.047985\t Accuracy:96.143%\n",
      "Epoch : 2 [19200/49000 (39%)]\tLoss: 0.265319\t Accuracy:96.095%\n",
      "Epoch : 2 [20800/49000 (42%)]\tLoss: 0.036658\t Accuracy:96.030%\n",
      "Epoch : 2 [22400/49000 (46%)]\tLoss: 0.397920\t Accuracy:95.966%\n",
      "Epoch : 2 [24000/49000 (49%)]\tLoss: 0.065085\t Accuracy:95.943%\n",
      "Epoch : 2 [25600/49000 (52%)]\tLoss: 0.044122\t Accuracy:95.872%\n",
      "Epoch : 2 [27200/49000 (55%)]\tLoss: 0.419095\t Accuracy:95.884%\n",
      "Epoch : 2 [28800/49000 (59%)]\tLoss: 0.017014\t Accuracy:95.939%\n",
      "Epoch : 2 [30400/49000 (62%)]\tLoss: 0.113032\t Accuracy:95.929%\n",
      "Epoch : 2 [32000/49000 (65%)]\tLoss: 0.055087\t Accuracy:95.948%\n",
      "Epoch : 2 [33600/49000 (69%)]\tLoss: 0.094590\t Accuracy:95.932%\n",
      "Epoch : 2 [35200/49000 (72%)]\tLoss: 0.049377\t Accuracy:95.927%\n",
      "Epoch : 2 [36800/49000 (75%)]\tLoss: 0.094736\t Accuracy:95.941%\n",
      "Epoch : 2 [38400/49000 (78%)]\tLoss: 0.051207\t Accuracy:95.941%\n",
      "Epoch : 2 [40000/49000 (82%)]\tLoss: 0.114483\t Accuracy:95.938%\n",
      "Epoch : 2 [41600/49000 (85%)]\tLoss: 0.151812\t Accuracy:95.984%\n",
      "Epoch : 2 [43200/49000 (88%)]\tLoss: 0.041639\t Accuracy:96.017%\n",
      "Epoch : 2 [44800/49000 (91%)]\tLoss: 0.078769\t Accuracy:96.032%\n",
      "Epoch : 2 [46400/49000 (95%)]\tLoss: 0.009515\t Accuracy:96.076%\n",
      "Epoch : 2 [48000/49000 (98%)]\tLoss: 0.096647\t Accuracy:96.084%\n",
      "Epoch : 3 [0/49000 (0%)]\tLoss: 0.209245\t Accuracy:93.750%\n",
      "Epoch : 3 [1600/49000 (3%)]\tLoss: 0.084666\t Accuracy:96.998%\n",
      "Epoch : 3 [3200/49000 (7%)]\tLoss: 0.039668\t Accuracy:96.968%\n",
      "Epoch : 3 [4800/49000 (10%)]\tLoss: 0.318479\t Accuracy:96.875%\n",
      "Epoch : 3 [6400/49000 (13%)]\tLoss: 0.025376\t Accuracy:96.859%\n",
      "Epoch : 3 [8000/49000 (16%)]\tLoss: 0.345140\t Accuracy:96.688%\n",
      "Epoch : 3 [9600/49000 (20%)]\tLoss: 0.012624\t Accuracy:96.532%\n",
      "Epoch : 3 [11200/49000 (23%)]\tLoss: 0.217137\t Accuracy:96.590%\n",
      "Epoch : 3 [12800/49000 (26%)]\tLoss: 0.204481\t Accuracy:96.672%\n",
      "Epoch : 3 [14400/49000 (29%)]\tLoss: 0.122037\t Accuracy:96.667%\n",
      "Epoch : 3 [16000/49000 (33%)]\tLoss: 0.119419\t Accuracy:96.682%\n",
      "Epoch : 3 [17600/49000 (36%)]\tLoss: 0.021901\t Accuracy:96.688%\n",
      "Epoch : 3 [19200/49000 (39%)]\tLoss: 0.285990\t Accuracy:96.750%\n",
      "Epoch : 3 [20800/49000 (42%)]\tLoss: 0.000918\t Accuracy:96.789%\n",
      "Epoch : 3 [22400/49000 (46%)]\tLoss: 0.189619\t Accuracy:96.674%\n",
      "Epoch : 3 [24000/49000 (49%)]\tLoss: 0.089919\t Accuracy:96.646%\n",
      "Epoch : 3 [25600/49000 (52%)]\tLoss: 0.003621\t Accuracy:96.625%\n",
      "Epoch : 3 [27200/49000 (55%)]\tLoss: 0.317268\t Accuracy:96.677%\n",
      "Epoch : 3 [28800/49000 (59%)]\tLoss: 0.191053\t Accuracy:96.688%\n",
      "Epoch : 3 [30400/49000 (62%)]\tLoss: 0.093661\t Accuracy:96.629%\n",
      "Epoch : 3 [32000/49000 (65%)]\tLoss: 0.009178\t Accuracy:96.644%\n",
      "Epoch : 3 [33600/49000 (69%)]\tLoss: 0.137306\t Accuracy:96.688%\n",
      "Epoch : 3 [35200/49000 (72%)]\tLoss: 0.118752\t Accuracy:96.682%\n",
      "Epoch : 3 [36800/49000 (75%)]\tLoss: 0.334662\t Accuracy:96.680%\n",
      "Epoch : 3 [38400/49000 (78%)]\tLoss: 0.072715\t Accuracy:96.701%\n",
      "Epoch : 3 [40000/49000 (82%)]\tLoss: 0.020828\t Accuracy:96.653%\n",
      "Epoch : 3 [41600/49000 (85%)]\tLoss: 0.066488\t Accuracy:96.678%\n",
      "Epoch : 3 [43200/49000 (88%)]\tLoss: 0.428854\t Accuracy:96.678%\n",
      "Epoch : 3 [44800/49000 (91%)]\tLoss: 0.125550\t Accuracy:96.685%\n",
      "Epoch : 3 [46400/49000 (95%)]\tLoss: 0.005727\t Accuracy:96.718%\n",
      "Epoch : 3 [48000/49000 (98%)]\tLoss: 0.221380\t Accuracy:96.736%\n",
      "Epoch : 4 [0/49000 (0%)]\tLoss: 0.019204\t Accuracy:100.000%\n",
      "Epoch : 4 [1600/49000 (3%)]\tLoss: 0.009241\t Accuracy:97.488%\n",
      "Epoch : 4 [3200/49000 (7%)]\tLoss: 0.226558\t Accuracy:97.030%\n",
      "Epoch : 4 [4800/49000 (10%)]\tLoss: 0.137561\t Accuracy:96.999%\n",
      "Epoch : 4 [6400/49000 (13%)]\tLoss: 0.030600\t Accuracy:97.077%\n",
      "Epoch : 4 [8000/49000 (16%)]\tLoss: 0.177124\t Accuracy:96.925%\n",
      "Epoch : 4 [9600/49000 (20%)]\tLoss: 0.156488\t Accuracy:96.885%\n",
      "Epoch : 4 [11200/49000 (23%)]\tLoss: 0.280535\t Accuracy:96.813%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 4 [12800/49000 (26%)]\tLoss: 0.485813\t Accuracy:96.875%\n",
      "Epoch : 4 [14400/49000 (29%)]\tLoss: 0.022930\t Accuracy:96.910%\n",
      "Epoch : 4 [16000/49000 (33%)]\tLoss: 0.043097\t Accuracy:96.894%\n",
      "Epoch : 4 [17600/49000 (36%)]\tLoss: 0.005847\t Accuracy:96.886%\n",
      "Epoch : 4 [19200/49000 (39%)]\tLoss: 0.220363\t Accuracy:96.906%\n",
      "Epoch : 4 [20800/49000 (42%)]\tLoss: 0.004355\t Accuracy:96.913%\n",
      "Epoch : 4 [22400/49000 (46%)]\tLoss: 0.076977\t Accuracy:96.866%\n",
      "Epoch : 4 [24000/49000 (49%)]\tLoss: 0.036896\t Accuracy:96.850%\n",
      "Epoch : 4 [25600/49000 (52%)]\tLoss: 0.017019\t Accuracy:96.832%\n",
      "Epoch : 4 [27200/49000 (55%)]\tLoss: 0.392278\t Accuracy:96.827%\n",
      "Epoch : 4 [28800/49000 (59%)]\tLoss: 0.010164\t Accuracy:96.868%\n",
      "Epoch : 4 [30400/49000 (62%)]\tLoss: 0.065720\t Accuracy:96.849%\n",
      "Epoch : 4 [32000/49000 (65%)]\tLoss: 0.001300\t Accuracy:96.856%\n",
      "Epoch : 4 [33600/49000 (69%)]\tLoss: 0.066023\t Accuracy:96.854%\n",
      "Epoch : 4 [35200/49000 (72%)]\tLoss: 0.080354\t Accuracy:96.847%\n",
      "Epoch : 4 [36800/49000 (75%)]\tLoss: 0.148589\t Accuracy:96.829%\n",
      "Epoch : 4 [38400/49000 (78%)]\tLoss: 0.142794\t Accuracy:96.878%\n",
      "Epoch : 4 [40000/49000 (82%)]\tLoss: 0.113222\t Accuracy:96.885%\n",
      "Epoch : 4 [41600/49000 (85%)]\tLoss: 0.141147\t Accuracy:96.913%\n",
      "Epoch : 4 [43200/49000 (88%)]\tLoss: 0.004317\t Accuracy:96.954%\n",
      "Epoch : 4 [44800/49000 (91%)]\tLoss: 0.058849\t Accuracy:96.958%\n",
      "Epoch : 4 [46400/49000 (95%)]\tLoss: 0.066506\t Accuracy:96.957%\n",
      "Epoch : 4 [48000/49000 (98%)]\tLoss: 0.180277\t Accuracy:96.954%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(SEED)\n",
    "fit(mlp, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В качестве метрики качества возьмем обычный accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.956% \n"
     ]
    }
   ],
   "source": [
    "def evaluate(model):\n",
    "    correct = 0 \n",
    "    for test_imgs, test_labels in test_loader:\n",
    "        test_imgs = Variable(test_imgs).float()\n",
    "        output = model(test_imgs)\n",
    "        predicted = torch.max(output,1)[1]\n",
    "        correct += (predicted == test_labels).sum()\n",
    "    print(\"Test accuracy:{:.3f}% \".format( float(correct) / (len(test_loader)*BATCH_SIZE)))\n",
    "\n",
    "evaluate(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Весьма неплохое качество, учитывая, что мы почти ничего не придумывали с сетью.\n",
    "\n",
    "Посмотрим, сколько параметров нам потребовалось, чтобы получить это качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_weights(model):\n",
    "    result = 0\n",
    "    for layer in model.children():\n",
    "        result += len(layer.weight.reshape(-1))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "222000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_weights(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что полносвязные слои достаточно тяжелые и всего три слоя дали нам больше чем 200 000 параметров. Попробуем ужать это число, не сильно уменьшим при этом качество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Удаляем связи внутри сети\n",
    "\n",
    "Для того, чтобы начать оптимизировать размер сети, нам нужен инструментарий для удаления связей внутри нашей модели.\n",
    "\n",
    "Нам потребуется особый полносвязный слой, в котором мы можем отключать конкретные веса. Используя такие слои, соберем такую же архитектруру с тремя полносвязными.\n",
    "\n",
    "Отключать сами веса мы будем исходя из их абсолютного значения - задавая пороговое значение, мы будем занулять только те веса, которые меньше этого значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class MaskedLinear(nn.Module):\n",
    "    def __init__(self, in_size, out_size):\n",
    "        super(MaskedLinear, self).__init__()\n",
    "        # Обычный полносвязный слой\n",
    "        self._linear = nn.Linear(in_size, out_size) \n",
    "        # Маска для слоя. Для связи из оригинального слоя, здесь будут хранится 0 и 1. \n",
    "        # 1 - связь действует, 0 - связь не действует.\n",
    "        self._mask = nn.Linear(in_size, out_size)\n",
    "        # Изначально все числа в маске - 1. То есть изначально мы не выключаем вообще никакие веса\n",
    "        self._mask.weight.data = torch.ones(self._mask.weight.size())\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Чтобы применить этот слой, нужно вначале умножить веса на маску. \n",
    "        # Тогда те веса, которые мы выключили, занулятся, что и будет означать, что мы их просто выкинули\n",
    "        self._linear.weight.data = torch.mul(self._linear.weight, self._mask.weight)\n",
    "        return self._linear(x)\n",
    "    \n",
    "    def prune(self, threshold):\n",
    "        # Для того, чтобы выключить часть связей задается threshold\n",
    "        # Если значение веса по модулю в сети меньше, чем threshold, то мы его выключаем, а значит выставляем 0 в маске.\n",
    "        self._mask.weight.data = torch.mul(torch.gt(torch.abs(self._linear.weight), threshold).float(), self._mask.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Составляем точно такую же архитектуру, но используя наши особенные полносвязные слои, в которых мы можем отключать веса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class AutoCompressMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoCompressMLP, self).__init__()\n",
    "        self.linear1 = MaskedLinear(784,250)\n",
    "        self.linear2 = MaskedLinear(250,100)\n",
    "        self.linear3 = MaskedLinear(100,10)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = self.linear3(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "    \n",
    "    def prune(self, threshold):\n",
    "        self.linear1.prune(threshold)\n",
    "        self.linear2.prune(threshold)\n",
    "        self.linear3.prune(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы удалить какую-то долю связей из сети, необходимо вначале подсчитать необходимое пороговое значение. \n",
    "\n",
    "Так, чтобы удалить N% связей по этой схеме, необходимо найти такое число, чтобы ровно N% связей имело вес меньше этого числа по модулю. Другими словами найти N-перцентиль.\n",
    "\n",
    "Напишем функцию, которая будет искать такое пороговое значение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_threshhold(model, rate):\n",
    "    all_weights = torch.Tensor()\n",
    "    for layer in model.children():\n",
    "        all_weights = torch.cat( (layer._linear.weight.view(-1), all_weights.view(-1)) )\n",
    "    abs_weight = torch.abs(all_weights)\n",
    "    \n",
    "    return np.percentile(abs_weight.detach().cpu().numpy(), rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018921107985079288"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acmlp = AutoCompressMLP()\n",
    "t = calc_threshhold(acmlp, 50.0)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы следить за тем, сколько параметров осталось внури нашей сети, нам потребуется немного другая функция подсчета активных весов, учитываящая маску."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_pruned_weights(model):\n",
    "    result = 0\n",
    "    for layer in model.children():\n",
    "        result += torch.sum(layer._mask.weight.reshape(-1))\n",
    "    return int(result.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "111000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acmlp.prune(t)\n",
    "calc_pruned_weights(acmlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итеративное прореживание\n",
    "\n",
    "Идин из способов сжатия нейронных сетей - итеративное прореживание (Incremental Magnitude Pruning). Он достаточно ресурсоемкий, однако позволяет достаточно несложными методами добиться неплохого результата."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "acmlp = AutoCompressMLP()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вначале просто обучим нашу модель, никаким образом ее не модифицируя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/49000 (0%)]\tLoss: 12.148988\t Accuracy:3.125%\n",
      "Epoch : 0 [1600/49000 (3%)]\tLoss: 0.237205\t Accuracy:67.525%\n",
      "Epoch : 0 [3200/49000 (7%)]\tLoss: 0.358010\t Accuracy:76.269%\n",
      "Epoch : 0 [4800/49000 (10%)]\tLoss: 0.351805\t Accuracy:80.215%\n",
      "Epoch : 0 [6400/49000 (13%)]\tLoss: 0.419410\t Accuracy:82.494%\n",
      "Epoch : 0 [8000/49000 (16%)]\tLoss: 0.394660\t Accuracy:83.914%\n",
      "Epoch : 0 [9600/49000 (20%)]\tLoss: 0.127043\t Accuracy:84.904%\n",
      "Epoch : 0 [11200/49000 (23%)]\tLoss: 0.453196\t Accuracy:85.791%\n",
      "Epoch : 0 [12800/49000 (26%)]\tLoss: 0.129024\t Accuracy:86.300%\n",
      "Epoch : 0 [14400/49000 (29%)]\tLoss: 0.390616\t Accuracy:86.918%\n",
      "Epoch : 0 [16000/49000 (33%)]\tLoss: 0.394425\t Accuracy:87.406%\n",
      "Epoch : 0 [17600/49000 (36%)]\tLoss: 0.159227\t Accuracy:87.721%\n",
      "Epoch : 0 [19200/49000 (39%)]\tLoss: 0.622173\t Accuracy:88.036%\n",
      "Epoch : 0 [20800/49000 (42%)]\tLoss: 0.122171\t Accuracy:88.431%\n",
      "Epoch : 0 [22400/49000 (46%)]\tLoss: 0.733558\t Accuracy:88.788%\n",
      "Epoch : 0 [24000/49000 (49%)]\tLoss: 0.181110\t Accuracy:89.023%\n",
      "Epoch : 0 [25600/49000 (52%)]\tLoss: 0.145849\t Accuracy:89.221%\n",
      "Epoch : 0 [27200/49000 (55%)]\tLoss: 0.546040\t Accuracy:89.435%\n",
      "Epoch : 0 [28800/49000 (59%)]\tLoss: 0.043622\t Accuracy:89.647%\n",
      "Epoch : 0 [30400/49000 (62%)]\tLoss: 0.186678\t Accuracy:89.807%\n",
      "Epoch : 0 [32000/49000 (65%)]\tLoss: 0.070862\t Accuracy:90.001%\n",
      "Epoch : 0 [33600/49000 (69%)]\tLoss: 0.369971\t Accuracy:90.203%\n",
      "Epoch : 0 [35200/49000 (72%)]\tLoss: 0.072355\t Accuracy:90.344%\n",
      "Epoch : 0 [36800/49000 (75%)]\tLoss: 0.069097\t Accuracy:90.533%\n",
      "Epoch : 0 [38400/49000 (78%)]\tLoss: 0.170482\t Accuracy:90.680%\n",
      "Epoch : 0 [40000/49000 (82%)]\tLoss: 0.249632\t Accuracy:90.790%\n",
      "Epoch : 0 [41600/49000 (85%)]\tLoss: 0.124974\t Accuracy:90.916%\n",
      "Epoch : 0 [43200/49000 (88%)]\tLoss: 0.128102\t Accuracy:91.004%\n",
      "Epoch : 0 [44800/49000 (91%)]\tLoss: 0.495274\t Accuracy:91.107%\n",
      "Epoch : 0 [46400/49000 (95%)]\tLoss: 0.011929\t Accuracy:91.243%\n",
      "Epoch : 0 [48000/49000 (98%)]\tLoss: 0.255840\t Accuracy:91.362%\n",
      "Epoch : 1 [0/49000 (0%)]\tLoss: 0.152836\t Accuracy:93.750%\n",
      "Epoch : 1 [1600/49000 (3%)]\tLoss: 0.126703\t Accuracy:94.240%\n",
      "Epoch : 1 [3200/49000 (7%)]\tLoss: 0.038982\t Accuracy:94.338%\n",
      "Epoch : 1 [4800/49000 (10%)]\tLoss: 0.270748\t Accuracy:94.516%\n",
      "Epoch : 1 [6400/49000 (13%)]\tLoss: 0.096638\t Accuracy:94.776%\n",
      "Epoch : 1 [8000/49000 (16%)]\tLoss: 0.381329\t Accuracy:94.709%\n",
      "Epoch : 1 [9600/49000 (20%)]\tLoss: 0.256479\t Accuracy:94.518%\n",
      "Epoch : 1 [11200/49000 (23%)]\tLoss: 0.282531\t Accuracy:94.676%\n",
      "Epoch : 1 [12800/49000 (26%)]\tLoss: 0.200516\t Accuracy:94.810%\n",
      "Epoch : 1 [14400/49000 (29%)]\tLoss: 0.399102\t Accuracy:94.817%\n",
      "Epoch : 1 [16000/49000 (33%)]\tLoss: 0.204111\t Accuracy:94.904%\n",
      "Epoch : 1 [17600/49000 (36%)]\tLoss: 0.012753\t Accuracy:94.947%\n",
      "Epoch : 1 [19200/49000 (39%)]\tLoss: 0.505695\t Accuracy:94.972%\n",
      "Epoch : 1 [20800/49000 (42%)]\tLoss: 0.009710\t Accuracy:94.993%\n",
      "Epoch : 1 [22400/49000 (46%)]\tLoss: 0.226641\t Accuracy:94.945%\n",
      "Epoch : 1 [24000/49000 (49%)]\tLoss: 0.059713\t Accuracy:94.919%\n",
      "Epoch : 1 [25600/49000 (52%)]\tLoss: 0.041901\t Accuracy:94.940%\n",
      "Epoch : 1 [27200/49000 (55%)]\tLoss: 0.420391\t Accuracy:94.969%\n",
      "Epoch : 1 [28800/49000 (59%)]\tLoss: 0.093593\t Accuracy:95.006%\n",
      "Epoch : 1 [30400/49000 (62%)]\tLoss: 0.078980\t Accuracy:95.009%\n",
      "Epoch : 1 [32000/49000 (65%)]\tLoss: 0.123679\t Accuracy:95.027%\n",
      "Epoch : 1 [33600/49000 (69%)]\tLoss: 0.140978\t Accuracy:95.082%\n",
      "Epoch : 1 [35200/49000 (72%)]\tLoss: 0.283661\t Accuracy:95.041%\n",
      "Epoch : 1 [36800/49000 (75%)]\tLoss: 0.004024\t Accuracy:95.083%\n",
      "Epoch : 1 [38400/49000 (78%)]\tLoss: 0.067978\t Accuracy:95.145%\n",
      "Epoch : 1 [40000/49000 (82%)]\tLoss: 0.128421\t Accuracy:95.176%\n",
      "Epoch : 1 [41600/49000 (85%)]\tLoss: 0.006990\t Accuracy:95.218%\n",
      "Epoch : 1 [43200/49000 (88%)]\tLoss: 0.028105\t Accuracy:95.228%\n",
      "Epoch : 1 [44800/49000 (91%)]\tLoss: 0.465995\t Accuracy:95.242%\n",
      "Epoch : 1 [46400/49000 (95%)]\tLoss: 0.010773\t Accuracy:95.275%\n",
      "Epoch : 1 [48000/49000 (98%)]\tLoss: 0.097536\t Accuracy:95.309%\n",
      "Epoch : 2 [0/49000 (0%)]\tLoss: 0.089579\t Accuracy:96.875%\n",
      "Epoch : 2 [1600/49000 (3%)]\tLoss: 0.056793\t Accuracy:95.527%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(SEED)\n",
    "fit(acmlp, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(acmlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отлично, получили примерно такую же модель, как и в самом начале. \n",
    "\n",
    "Сейчас модель уже имеет хорошие веса для предсказаний. Теперь попробуем убрать из нее 50% связей и посмотрим, насколько ей удастся сохранить качество.\n",
    "\n",
    "Как уже отмечалось, отключим 50% наиболее слабых связей в сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "acmlp_test1 = copy.deepcopy(acmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t_50 = calc_threshhold(acmlp_test1, 50.0)\n",
    "acmlp_test1.prune(t_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(acmlp_test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что таким образом выкинутые веса почти не повлияли на качество сети. При этом мы выкинули половину всех коэффициентов! Весьма неплохой результат.\n",
    "\n",
    "Давайте посмотрим, можем ли мы с таким же успехом выкинуть 90% сети?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "acmlp_test2 = copy.deepcopy(acmlp)\n",
    "\n",
    "t_90 = calc_threshhold(acmlp_test2, 90.0)\n",
    "acmlp_test2.prune(t_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(acmlp_test2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Увы, так просто выкинуть 90% и оставить качество не получается. Будем использовать более хитрый подход.\n",
    "\n",
    "Будет идти с шагом в 10%. Каждый раз будет отключать внутри сети 10% связей. После отключения, оставшиеся веса дообучим на всех данных используя всего одну эпоху. Ожидается, что так как мы выкинули за один раз не очень много, то оставшиеся связи \"перехватят\" ответственность тех слабых, которые мы только что отключили.\n",
    "\n",
    "Таким образом за P таких итераций мы выкинем 10P% всей сети и не должны при этом потерять сильно в качестве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def smart_prune(model, train_loader, compress_rate):\n",
    "    # Создаем именно новую модель, старую не трогаем\n",
    "    model = copy.deepcopy(model)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    \n",
    "    for rate in range(0, compress_rate+1, 10):  # Идем с шагом в 10%\n",
    "        t = calc_threshhold(model, float(rate))  # Считаем очередное пороговое значение\n",
    "        model.prune(t)  # Отключаем слабые связи\n",
    "        correct = 0\n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):  # Далее дообучаем модель как обычно в течение одной эпохи\n",
    "            var_X_batch = Variable(X_batch).float()\n",
    "            var_y_batch = Variable(y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(var_X_batch)\n",
    "            loss = error(output, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicted = torch.max(output.data, 1)[1] \n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            if batch_idx % 20 == 0:\n",
    "                print('Rate : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                    rate, batch_idx*len(X_batch), len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.data, float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем для начала выкинуть 70% таким образом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "pruned_model = smart_prune(acmlp, train_loader, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На моем компьютере получилось качество около 0.97. Формально это даже чуточку лучше, чем оригинальная модель! Получается, что лишние веса в оригинальной модели могли мешали выявить зависимость в данных. \n",
    "\n",
    "Давайте посчитаем количество ненулевых весов в модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "calc_pruned_weights(acmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "calc_pruned_weights(pruned_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оставили около 60 000 весов, мы получили почти такое же качество для модели!\n",
    "\n",
    "Можем ли мы таким же образом выкинуть 90%?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "pruned_model_90 = smart_prune(acmlp, train_loader, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(pruned_model_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "calc_pruned_weights(pruned_model_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выкинув большую часть сети, мы все еще имеем относительно неплохое качество, хоть и меньше, чем изначально. \n",
    "\n",
    "Вполне возможно проблема в том, что мы слишком агрессивно удаляем связи, когда их остается совсем мало. Давайте попробуем более аккуратные шаги.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def smart_prune_shed(model, train_loader, schedule):\n",
    "    # Создаем именно новую модель, старую не трогаем\n",
    "    model = copy.deepcopy(model)\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    \n",
    "    for rate, epochs in schedule:  # Идем шагами, согласно тому расписанию, которое передали в функцию\n",
    "        t = calc_threshhold(model, float(rate))  # Считаем очередное пороговое значение\n",
    "        model.prune(t)  # Отключаем слабые связи\n",
    "        for i in range(epochs):\n",
    "            correct = 0\n",
    "            for batch_idx, (X_batch, y_batch) in enumerate(train_loader):  # Далее дообучаем модель как обычно в течение указанного количества эпох\n",
    "                var_X_batch = Variable(X_batch).float()\n",
    "                var_y_batch = Variable(y_batch)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(var_X_batch)\n",
    "                loss = error(output, var_y_batch)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                predicted = torch.max(output.data, 1)[1] \n",
    "                correct += (predicted == var_y_batch).sum()\n",
    "                if batch_idx % 20 == 0:\n",
    "                    print('Rate : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                        rate, batch_idx*len(X_batch), len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.data, float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "pruned_model_90 = smart_prune_shed(acmlp, train_loader, [\n",
    "    (0, 1), \n",
    "    (20, 1), \n",
    "    (40, 1), \n",
    "    (50, 1), \n",
    "    (60, 1), \n",
    "    (70, 1), \n",
    "    (75, 1), \n",
    "    (80, 2), \n",
    "    (83, 2), \n",
    "    (85, 2), \n",
    "    (86, 2), \n",
    "    (87, 2), \n",
    "    (88, 2), \n",
    "    (89, 2), \n",
    "    (90, 2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(pruned_model_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "calc_pruned_weights(pruned_model_90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтож, это оригинальное качество за всего 10% сети.\n",
    "\n",
    "Ради интереса попробуем \"дожать до победы\" и удалим 99%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "pruned_model_99 = smart_prune_shed(pruned_model_90, train_loader, [\n",
    "    (90, 2),\n",
    "    (92, 2),\n",
    "    (94, 2),\n",
    "    (95, 2),\n",
    "    (96, 2),\n",
    "    (97, 2),\n",
    "    (98, 2),\n",
    "    (99, 2)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(pruned_model_99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "calc_pruned_weights(pruned_model_99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что метод все таки имеет свои ограничения. По логу видно, что где-то в районе 94% мы видимо задели какой-то очень важный участок сети, после удаления которого она уже не смогла восстановится.\n",
    "\n",
    "Однако результат в 90% - это тоже вполне неплохо!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Готовые реализации\n",
    "\n",
    "Сама техника достаточно популярна и часто имеет уже готовые реализации. В Pytorch имеется отдельный модуль для проведения прореживания сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.utils.prune as prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class PytorchPrunedMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PytorchPrunedMLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(784,250)\n",
    "        self.linear2 = nn.Linear(250,100)\n",
    "        self.linear3 = nn.Linear(100,10)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = self.linear3(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "    \n",
    "    def prune(self, rate):\n",
    "        # Используем l1_unstructured вместо нашего подхода\n",
    "        # unstructured говорит о том, что нет ограничений на удаляемые веса\n",
    "        # l1 говорит о том, что нужно смотреть на модуль веса\n",
    "        prune.l1_unstructured(self.linear1, 'weight', amount=rate)\n",
    "        prune.l1_unstructured(self.linear2, 'weight', amount=rate)\n",
    "        prune.l1_unstructured(self.linear3, 'weight', amount=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "ppmlp = PytorchPrunedMLP()\n",
    "fit(ppmlp, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(ppmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ppmlp.prune(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(ppmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calc_pytorch_weights(model):\n",
    "    result = 0\n",
    "    for layer in model.children():\n",
    "        if hasattr(layer, 'weight_mask'):\n",
    "            result += int(torch.sum(layer.weight_mask.reshape(-1)).item())\n",
    "        else:\n",
    "            result += len(layer.weight.reshape(-1))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "calc_pytorch_weights(ppmlp) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Точно таким же образом мы только что выкинули 50% самых слабый весов из сети.\n",
    "\n",
    "# Групповое (структурированное) прореживание\n",
    "\n",
    "В библиотеке реализованы также и более продвинутые версии этого алгоритма. Например мы можем делать более структурированное прореживание, удаляя не единичные связи, а целиком нейроны из сети. \n",
    "\n",
    "Для того, чтобы понять, насколько тот или иной нейрон важен для работы сети, будем смотреть на все веса, связанные с ним. Если веса значительно отличаются от нуля, значит нейрон важный, если близки к нулю - значит скорее всего его можно удалить.\n",
    "\n",
    "Понимать, насколько группа нейронов близка к нулю можно разными способами. Наиболее популярный - L-нормы. Так например при L1 мы будем смотреть на сумму по модулю все весов для нейрона, а при L2 - на корень из суммы квадратов весов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class StructuredPrunedMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StructuredPrunedMLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(784,250)\n",
    "        self.linear2 = nn.Linear(250,100)\n",
    "        self.linear3 = nn.Linear(100,10)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = self.linear3(X)\n",
    "        return F.log_softmax(X, dim=1)\n",
    "    \n",
    "    def prune(self, rate):\n",
    "        # Используем ln_structured для удаления нейронов целиком\n",
    "        # Для оценивания значимости нейрона будем использовать L2, поэтому указываем n=2\n",
    "        # Указываем dim=1 - это укажет, как именно нужно групировать веса. Для dim=1 - это группировка по нейронам\n",
    "        prune.ln_structured(self.linear1, 'weight', amount=rate, n=2, dim=1)\n",
    "        prune.ln_structured(self.linear2, 'weight', amount=rate, n=2, dim=1)\n",
    "        # В последнем слое удалять нейроны нельзя, потому как они отвечают за ответ сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(SEED)\n",
    "spmlp = StructuredPrunedMLP()\n",
    "fit(spmlp, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(spmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spmlp.prune(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "evaluate(spmlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "calc_pytorch_weights(spmlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно посмотреть на устройство весов в наших последних двух моделях\n",
    "\n",
    "У модели, которую прореживали по весам, у каждого нейрона отключены какие-то элементы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ppmlp.linear1.weight_mask.T[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У модели, которую прореживали по нейронам, нейрон или отключен совсем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spmlp.linear1.weight_mask.T[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Или работает целиком"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "spmlp.linear1.weight_mask.T[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
