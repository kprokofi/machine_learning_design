{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<img src=\"img/swarm-logo.png\">\n",
    "<small>https://medium.com/southbridge/%D0%BE%D0%B4%D0%BD%D0%BE%D1%80%D0%B0%D0%B7%D0%BE%D0%B2%D1%8B%D0%B5-%D0%BA%D0%BE%D0%BD%D1%82%D0%B5%D0%B9%D0%BD%D0%B5%D1%80%D1%8B-%D0%B2-docker-swarm-a14a60117dec</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Docker Swarm - это система оркестрации множества контейнеров на множестве машин. В ее обязаности входит слежение за состоянием контейнеров, перемещение их между машинами, обеспечение сетевой связанности между машинами, предоставление пользователю единого интерфейса для работы с кластером и другие технические задачи по поддержанию работоспособности кластера.\n",
    "\n",
    "Как и в предыдущей лабораторной, мы будем использовать сервис Play With Docker для демонстрации возможностей этого инструмента.\n",
    "\n",
    "# [Открыть Play With Docker](https://labs.play-with-docker.com/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Объединение в кластер\n",
    "\n",
    "Чтобы начать управлять кластером, вначале необходимо объединить разрозненные машины в единую систему. Для этого создадим сразу 3 виртуальные машины. В Play With Docker они будут называться node1, node2 и node3 и каждая их них будет иметь свой IP адрес.\n",
    "\n",
    "В Docker Swarm есть два типа машин - менеджеры и рабочие. Менеджеры занимаются управлением всеми машинами. Если потребуется производить какие-либо манипуляции с кластером, это потребуется делать через машину-менеджера. \n",
    "Машины-рабочие не делают практически ничего, кроме как слушают команды от машин-менеджеров и беспрекословно выполняют их команды.\n",
    "\n",
    "Для наших целей назначим node1 машиной-менеджером, а node2 и node3 - машинами-рабочими.\n",
    "\n",
    "Для этого на машине node1 запустим команду, которая инициализирует ее как менеджера. В этой команде необходимо будет указать IP адрес этой машины, через который она будет общаться с другими машинами кластера. В моем случае это 192.168.0.13 (в вашем случае IP может отличатся, внимательно посмотрите на то, какие IP выдал вам play with docker).\n",
    "\n",
    "```bash\n",
    "docker swarm init --advertise-addr 192.168.0.13\n",
    "```\n",
    "\n",
    "Отлично! Теперь к этому менеджеру необходимо подключить оставшиеся машины в качестве рабочих. После предыдущей команды на экране должна появится команда для подключения. Если вы ее уже потеряли, то можно руками еще раз спросить, какой токен требуется для подключения рабочих - для этого запустим следующую команду.\n",
    "\n",
    "```bash\n",
    "docker swarm join-token -q worker\n",
    "```\n",
    "\n",
    "Формируем токен, переключаемся на node2 и запускаем команду на подключение. Для меня команда выглядит следующим образом:\n",
    "```bash\n",
    "docker swarm join --token SWMTKN-1-3kvfsmba4zi7zxwcixwf4obzlqyd1jyrhx9xt365lzbf7nzwp8-e0fyc576f5c7x7x9mwr960lmy 192.168.0.13:2377\n",
    "```\n",
    "\n",
    "Важно, что токен может отличатся, а также адрес `192.168.0.13` (адрес менеджера к которому подключаемся) также может отличаться - вставьте туда актуальный адрес node1.\n",
    "\n",
    "Если все сделано правильно, то машина должна была подключиться к менеджеру в качестве рабочего.\n",
    "\n",
    "Точно такую же операцию необходимо произвести для машины node3.\n",
    "\n",
    "Поздравляю! Мы только что создали кластер!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создаем первый сервис\n",
    "\n",
    "Создавать сервисы в Docker Swarm можно просто из командной строки. Для этого есть команда `docker service create`.\n",
    "\n",
    "Запустим сервис по отображению состяния кластера, чтобы мы могли визуально следить за происходящим.\n",
    "\n",
    "```bash\n",
    "docker service create \\\n",
    "  --name=viz \\\n",
    "  --publish=8080:8080/tcp \\\n",
    "  --constraint=node.role==manager \\\n",
    "  --mount=type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \\\n",
    "  dockersamples/visualizer\n",
    "```\n",
    "\n",
    "Некоторые параметры запуска здесь выходят за рамки нашего курса, но все же дадим краткое описание того, что мы запускаем.\n",
    "* `--name` дает название для этого сервиса. Может быть любой строкой\n",
    "* `--publish=8080:8080/tcp` это уже знакомый нам проброс портов - все внешние соеднинения с 8080 мы отправляем на внутренний 8080\n",
    "* `--constraint=node.role==manager` говорит о том, что этот сервис можно запускать только на машинах-менеджерах. Это необходимо, так как только менеджеры знают информацию для отображения\n",
    "* `--mount=type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock` это уже знакомый проброс файлов и директорий внутрь контейнера. Визуализатору требуется доступ до докера, но так как сам он по себе находится внутри контейнера, нужно в явном виде предоставить ему доступ до докера в основной ОС\n",
    "* `dockersamples/visualizer` название докер-контейнера для запуска\n",
    "\n",
    "Запустив это команду на node1 (это важно, так как это машина-менеджер), в кластере развернется этот контейнер. Посмотреть состояние запущенных сервиов в кластере можно с помощью команды \n",
    "\n",
    "```bash\n",
    "docker service ls\n",
    "```\n",
    "\n",
    "Там должен отображаться наш новый сервис.\n",
    "\n",
    "Попробуем к нему подключится, открыв порт 8080 - должна отобразиться схема с отобржением трех машин и контейнеров на них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Особенности запуска на кластере\n",
    "\n",
    "### Общая сеть для связи между контейнерами\n",
    "\n",
    "По умолчанию общая сеть есть только у контейнеров на одной машине. Docker Swarm позволяет сделать общую сеть между контейнерами сразу на всем кластере. Тогда вне зависимости от того, где физически запущен сервис, он всегда сможет достучаться до любого другого контейнера. \n",
    "\n",
    "Создадим общую сеть на всем кластере и назовем ее backnet.\n",
    "```bash\n",
    "docker network create --driver overlay backnet\n",
    "```\n",
    "\n",
    "### Конфигурирование \n",
    "\n",
    "Монтирование файлов и директорий также работает только в рамках одной машины. Это означает, что если бы мы захотели запустить сервис, который требует внешней конфигурации (например nginx из предыдущей лабораторной), то пришлось бы положить руками этот файл конфигурации на все машины. К счастью, в docker swarm есть специальный механизм распределенного конфигрурирования. Он позволяет указать файл конфигурации и docker swarm самостоятельно передаст его на необходимые машины и подключит к нужным контейнерам.\n",
    "\n",
    "\n",
    "### Сборка конейтнера\n",
    "\n",
    "Сборка самого контейнера также происходит на одной машине. Это означает, что на других машинах просто не будет этого контейнера, чтобы запустить. Для того, чтобы решить эту проблему, мы можем собрать и выложить его в реестр образов. Для наших целей воспользуемся реестром от создателей Docker - Docker Hub. Этот сервис позволяет размещать у себя собранные пользователями контейнеры. \n",
    "\n",
    "Соберем и выложим наш контейнер с файловым сервисом.\n",
    "\n",
    "\n",
    "**file-server.sh**\n",
    "```bash\n",
    "export DIR=$(cat /etc/file-config.txt)\n",
    "\n",
    "mkdir -p $DIR\n",
    "\n",
    "python3 -m http.server --directory \"$DIR\" --bind 0.0.0.0 8080\n",
    "```\n",
    "\n",
    "**Dockerfile**\n",
    "```\n",
    "FROM python:3.7\n",
    "\n",
    "COPY file-server.sh file-server.sh\n",
    "\n",
    "ENTRYPOINT [\"bash\", \"file-server.sh\"]\n",
    "```\n",
    "\n",
    "Теперь соберем наш образ\n",
    "\n",
    "```bash\n",
    "docker build -t file-server:latest .\n",
    "```\n",
    "\n",
    "Осталось его выложить в Docker Hub. Для начала создадим публичный репозиторий - https://hub.docker.com/repository/create . Назовем его также - `file-server`. Каждый образ прикрепляется к именно автора. Так как мой никнейм на Docker Hub `adkosmos`, то полное название моего контейнера будет называться `adkosmos/file-server:latest`. В вашем случае необходимо будет использовать **ваш** никнейм.\n",
    "\n",
    "Авторизируемся на Docker Hub\n",
    "```bash\n",
    "docker login\n",
    "```\n",
    "\n",
    "Выложим собранный нами образ.\n",
    "\n",
    "```bash\n",
    "docker tag file-server:latest adkosmos/file-server:latest\n",
    "docker push adkosmos/file-server:latest\n",
    "```\n",
    "\n",
    "Поздравляю, вы только что выложили свой первый Docker образ!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Запуск на кластере\n",
    "\n",
    "Попробуем запустить наши сервисы, которые мы разрабатывали в предыдущей лабораторной. Для этого придется лишь немного модифицировать уже написанный docker-compose.yaml - необходимо подключить сервисы к созданной нами общей сети и добавить конфигурирование через docker swarm.\n",
    "\n",
    "**config.txt**\n",
    "```\n",
    "/shared/folder\n",
    "```\n",
    "\n",
    "**configuration.nginx**\n",
    "```\n",
    "user root;\n",
    "worker_processes  4;\n",
    "\n",
    "error_log  /var/log/nginx/error.log warn;\n",
    "pid        /var/run/nginx.pid;\n",
    "\n",
    "events {\n",
    "    worker_connections  4096;\n",
    "}\n",
    "\n",
    "http {\n",
    "    include       /etc/nginx/mime.types;\n",
    "    default_type  application/octet-stream;\n",
    "    log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n",
    "                      '$status $body_bytes_sent \"$http_referer\" '\n",
    "                      '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n",
    "\n",
    "    access_log  /var/log/nginx/access.log  main;\n",
    "\n",
    "    sendfile            on;\n",
    "    tcp_nopush          on;\n",
    "    keepalive_timeout   65;\n",
    "\n",
    "    server {\n",
    "        listen  8888;\n",
    "\n",
    "        location /file-server-1 {\n",
    "            proxy_pass http://file-server-1:8080;   # Перенаправляем в соседний контейнер по именно контейнера!\n",
    "            rewrite ^/file-server-1/(.*) /$1 break;  # Удаляем префикс /web-server-1\n",
    "        }\n",
    "        \n",
    "        location /file-server-2 {\n",
    "            proxy_pass http://file-server-2:8080;\n",
    "            rewrite ^/file-server-2/(.*) /$1 break;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Все эти файлы просто скопированы и никак не изменялись. Осталось создать docker-compose.yaml.\n",
    "\n",
    "**docker-compose.yaml**\n",
    "```yaml\n",
    "version: \"3.7\"\n",
    "\n",
    "services:\n",
    "  file-server-1:\n",
    "    image: adkosmos/file-server:latest  # Образ, который мы только что собрали и выложили\n",
    "    volumes:\n",
    "      - /machine-info:/shared/folder # Текущая директория\n",
    "    configs:\n",
    "      - source: file-server-config\n",
    "        target: /etc/file-config.txt\n",
    "  file-server-2:\n",
    "    image: adkosmos/file-server:latest  # Образ, который мы только что собрали и выложили\n",
    "    volumes:\n",
    "      - /etc:/shared/folder\n",
    "    configs:\n",
    "      - source: file-server-config\n",
    "        target: /etc/file-config.txt\n",
    "  proxy:\n",
    "    image: nginx:1.17\n",
    "    ports:\n",
    "      - 8888:8888\n",
    "    configs:\n",
    "      - source: nginx-config\n",
    "        target: /etc/nginx/nginx.conf  # Подключаем конфигурацию\n",
    "      \n",
    "networks:\n",
    "  backnet:\n",
    "    external: true  # Используем созданную извне сеть с названием backnet\n",
    "\n",
    "configs:  # Задаем файлы конфигураций, которые необходимо распределить по кластеру\n",
    "  file-server-config:\n",
    "    file: ./config.txt\n",
    "  nginx-config:\n",
    "    file: ./configuration.nginx \n",
    "```\n",
    "\n",
    "Чтобы мы могли видеть, на какой машине работает сервис, к которому мы подключились, создадим директорию /machine-info на каждой машине и создадим в них файлы с названиями машин (то есть node1, node2, node3). Эту директорию подключим к file-server-1.\n",
    "\n",
    "\n",
    "*на всех машинах*\n",
    "```bash\n",
    "mkdir -p /machine-info\n",
    "touch /machine-info/node-{N}\n",
    "```\n",
    "\n",
    "Настало время запускать наши сервисы. Назовем наш stack file-service.\n",
    "\n",
    "*на node1 (машине-менежеру)*\n",
    "```bash\n",
    "docker stack deploy --compose-file docker-compose.yaml file-service\n",
    "```\n",
    "\n",
    "Можешь проверить состояние с помощью команды\n",
    "```bash\n",
    "docker service ls\n",
    "```\n",
    "\n",
    "Через некоторое время все контейнеры должны запуститься!\n",
    "\n",
    "Чтобы посмотреть, как Docker Swarm раскидал конейнеры по машинам, откроем еще раз 8080 порт, на котором все еще работает визуализатор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверяем работу\n",
    "\n",
    "Откроем `8888` порт на node1 и там же добавим `/file-server-1/`. Можно видеть директорию с нашего файлового сервиса. \n",
    "\n",
    "Здесь важно отметить, что не важно, находятся nginx и file-server-1 на одной машине или нет. Благодаря общей внутренней сети кластера, они без проблем общаются.\n",
    "\n",
    "Так же стоит отметить, что не важно, к какой именно машине подключаться. Попробуем открыть `8888` порт на node2 и на node3 - результат будет точно такой же. Это происходит благодаря обобщенному интерфейса для пользователя. Запрос к любой машине будет перенаправлен в нужный контейнер."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Масштабируем наш сервис. \n",
    "\n",
    "Давайте удвоим каждый наш контейнер. Для этого необходимо указать параметр репликации в нашем `docker-compose.yaml`\n",
    "\n",
    "**docker-compose.yaml**\n",
    "```yaml\n",
    "version: \"3.7\"\n",
    "\n",
    "services:\n",
    "  file-server-1:\n",
    "    image: adkosmos/file-server:latest  # Образ, который мы только что собрали и выложили\n",
    "    deploy:\n",
    "      mode: replicated\n",
    "      replicas: 2  # Добавляем 2 реплики этого сервиса\n",
    "    volumes:\n",
    "      - /machine-info:/shared/folder # Текущая директория\n",
    "    configs:\n",
    "      - source: file-server-config\n",
    "        target: /etc/file-config.txt\n",
    "  file-server-2:\n",
    "    image: adkosmos/file-server:latest  # Образ, который мы только что собрали и выложили\n",
    "    deploy:\n",
    "      mode: replicated\n",
    "      replicas: 2  # Добавляем 2 реплики этого сервиса\n",
    "    volumes:\n",
    "      - /etc:/shared/folder\n",
    "    configs:\n",
    "      - source: file-server-config\n",
    "        target: /etc/file-config.txt\n",
    "  proxy:\n",
    "    image: nginx:1.17\n",
    "    deploy:\n",
    "      mode: replicated\n",
    "      replicas: 2  # Добавляем 2 реплики этого сервиса\n",
    "    ports:\n",
    "      - 8888:8888\n",
    "    configs:\n",
    "      - source: nginx-config\n",
    "        target: /etc/nginx/nginx.conf  # Подключаем конфигурацию\n",
    "\n",
    "networks:\n",
    "  backnet:\n",
    "    external: true  # Используем созданную извне сеть с названием backnet\n",
    "\n",
    "configs:  # Задаем файлы конфигураций, которые необходимо распределить по кластеру\n",
    "  file-server-config:\n",
    "    file: ./config.txt\n",
    "  nginx-config:\n",
    "    file: ./configuration.nginx \n",
    "```\n",
    "\n",
    "Перезапускаем наши сервисы\n",
    "\n",
    "```\n",
    "docker stack deploy --compose-file docker-compose.yaml file-service\n",
    "```\n",
    "\n",
    "Проверяем. `service ls` должен показать, что теперь у сервиса по две реплики\n",
    "```\n",
    "docker service ls\n",
    "```\n",
    "\n",
    "Открываем `8080` и смотрим, как теперь контейнеры распределены по кластеру.\n",
    "\n",
    "Попробуем теперь открыть `8888`. Так как теперь у нас два прокси-сервера, то кластер переадресует нас к любому из них. Более того, так как файловых серверов теперь тоже по два, прокси-сервер также будет перенаправлять нас к случайному их сервисов.\n",
    "\n",
    "Для того, чтобы это увидеть, пообновляйте путь `/file-server-1/` несколько раз. Если контейнеры физически запустились на разных машинах, то мы будем видеть разные файлы при обновлении.\n",
    "\n",
    "Вся схема работы нашей системы выглядит следующим образом:\n",
    "\n",
    "<img src=\"img/docker-swarm-file-service-scheme.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
