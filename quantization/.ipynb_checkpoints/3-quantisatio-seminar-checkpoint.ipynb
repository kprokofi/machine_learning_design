{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Квантизация нейронных сетей\n",
    "\n",
    "В этой лабораторной попробуем уменьшить размер нейронной сети, а также усторить ее работу, заменяя float на int внутри сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import copy\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from torch.quantization import QuantStub, DeQuantStub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3f75d16390>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED=9876\n",
    "torch.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вновь пробуем обучить сеть из трех полносвязных слоев на fashion mnist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = pd.read_csv(\"/data/fashion-mnist_train.csv\")\n",
    "test_csv = pd.read_csv(\"/data/fashion-mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0      2       0       0       0       0       0       0       0       0   \n",
       "1      9       0       0       0       0       0       0       0       0   \n",
       "2      6       0       0       0       0       0       0       0       5   \n",
       "3      0       0       0       0       1       2       0       0       0   \n",
       "4      3       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel9    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0        30        43   \n",
       "3       0    ...            3         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         1         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_csv['label'].values\n",
    "X_train = train_csv.drop(['label'],axis=1).values\n",
    "\n",
    "y_test = test_csv['label'].values\n",
    "X_test = test_csv.drop(['label'],axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb667967400>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[3].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fb6675ee128>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[4].reshape(28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "torch_X_train = torch.from_numpy(X_train).type(torch.LongTensor)\n",
    "torch_y_train = torch.from_numpy(y_train).type(torch.LongTensor)\n",
    "torch_X_test = torch.from_numpy(X_test).type(torch.LongTensor)\n",
    "torch_y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "\n",
    "train = torch.utils.data.TensorDataset(torch_X_train,torch_y_train)\n",
    "test = torch.utils.data.TensorDataset(torch_X_test,torch_y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = False)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear1): Linear(in_features=784, out_features=250, bias=True)\n",
      "  (linear2): Linear(in_features=250, out_features=100, bias=True)\n",
      "  (linear3): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(784,250)\n",
    "        self.linear2 = nn.Linear(250,100)\n",
    "        self.linear3 = nn.Linear(100,10)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = self.linear3(X)\n",
    "        return X\n",
    "\n",
    "mlp = MLP()\n",
    "print(mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, train_loader, epoch_number=5):\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    error = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epoch_number):\n",
    "        correct = 0\n",
    "        \n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            var_X_batch = Variable(X_batch).float()\n",
    "            var_y_batch = Variable(y_batch)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(var_X_batch)\n",
    "            loss = error(output, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicted = torch.max(output.data, 1)[1] \n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            if batch_idx % 200 == 0:\n",
    "                print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                    epoch, batch_idx*len(X_batch), len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.data, float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loader=test_loader):\n",
    "    correct = 0 \n",
    "    for test_imgs, test_labels in loader:\n",
    "        test_imgs = Variable(test_imgs).float()\n",
    "        \n",
    "        output = model(test_imgs)\n",
    "        predicted = torch.max(output,1)[1]\n",
    "        correct += (predicted == test_labels).sum()\n",
    "    print(\"Test accuracy:{:.3f}% \".format( float(correct) / (len(loader)*BATCH_SIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/60000 (0%)]\tLoss: 11.756062\t Accuracy:18.750%\n",
      "Epoch : 0 [6400/60000 (11%)]\tLoss: 0.620706\t Accuracy:69.667%\n",
      "Epoch : 0 [12800/60000 (21%)]\tLoss: 0.742245\t Accuracy:74.018%\n",
      "Epoch : 0 [19200/60000 (32%)]\tLoss: 0.313909\t Accuracy:75.790%\n",
      "Epoch : 0 [25600/60000 (43%)]\tLoss: 0.438836\t Accuracy:76.931%\n",
      "Epoch : 0 [32000/60000 (53%)]\tLoss: 0.558625\t Accuracy:77.791%\n",
      "Epoch : 0 [38400/60000 (64%)]\tLoss: 0.357680\t Accuracy:78.505%\n",
      "Epoch : 0 [44800/60000 (75%)]\tLoss: 0.413693\t Accuracy:78.988%\n",
      "Epoch : 0 [51200/60000 (85%)]\tLoss: 0.265867\t Accuracy:79.443%\n",
      "Epoch : 0 [57600/60000 (96%)]\tLoss: 0.315978\t Accuracy:79.775%\n",
      "Epoch : 1 [0/60000 (0%)]\tLoss: 0.553459\t Accuracy:84.375%\n",
      "Epoch : 1 [6400/60000 (11%)]\tLoss: 0.423689\t Accuracy:83.349%\n",
      "Epoch : 1 [12800/60000 (21%)]\tLoss: 0.699665\t Accuracy:83.541%\n",
      "Epoch : 1 [19200/60000 (32%)]\tLoss: 0.190550\t Accuracy:83.683%\n",
      "Epoch : 1 [25600/60000 (43%)]\tLoss: 0.260512\t Accuracy:83.844%\n",
      "Epoch : 1 [32000/60000 (53%)]\tLoss: 0.529210\t Accuracy:83.891%\n",
      "Epoch : 1 [38400/60000 (64%)]\tLoss: 0.401704\t Accuracy:84.016%\n",
      "Epoch : 1 [44800/60000 (75%)]\tLoss: 0.357541\t Accuracy:84.136%\n",
      "Epoch : 1 [51200/60000 (85%)]\tLoss: 0.228240\t Accuracy:84.287%\n",
      "Epoch : 1 [57600/60000 (96%)]\tLoss: 0.130492\t Accuracy:84.311%\n",
      "Epoch : 2 [0/60000 (0%)]\tLoss: 0.336314\t Accuracy:87.500%\n",
      "Epoch : 2 [6400/60000 (11%)]\tLoss: 0.337001\t Accuracy:84.375%\n",
      "Epoch : 2 [12800/60000 (21%)]\tLoss: 0.587588\t Accuracy:84.952%\n",
      "Epoch : 2 [19200/60000 (32%)]\tLoss: 0.222381\t Accuracy:85.004%\n",
      "Epoch : 2 [25600/60000 (43%)]\tLoss: 0.248443\t Accuracy:85.210%\n",
      "Epoch : 2 [32000/60000 (53%)]\tLoss: 0.504351\t Accuracy:85.115%\n",
      "Epoch : 2 [38400/60000 (64%)]\tLoss: 0.374137\t Accuracy:85.176%\n",
      "Epoch : 2 [44800/60000 (75%)]\tLoss: 0.352997\t Accuracy:85.290%\n",
      "Epoch : 2 [51200/60000 (85%)]\tLoss: 0.238472\t Accuracy:85.312%\n",
      "Epoch : 2 [57600/60000 (96%)]\tLoss: 0.319421\t Accuracy:85.274%\n",
      "Epoch : 3 [0/60000 (0%)]\tLoss: 0.349585\t Accuracy:84.375%\n",
      "Epoch : 3 [6400/60000 (11%)]\tLoss: 0.360603\t Accuracy:85.665%\n",
      "Epoch : 3 [12800/60000 (21%)]\tLoss: 0.511461\t Accuracy:85.926%\n",
      "Epoch : 3 [19200/60000 (32%)]\tLoss: 0.277780\t Accuracy:86.190%\n",
      "Epoch : 3 [25600/60000 (43%)]\tLoss: 0.302807\t Accuracy:86.255%\n",
      "Epoch : 3 [32000/60000 (53%)]\tLoss: 0.508188\t Accuracy:86.223%\n",
      "Epoch : 3 [38400/60000 (64%)]\tLoss: 0.361931\t Accuracy:86.111%\n",
      "Epoch : 3 [44800/60000 (75%)]\tLoss: 0.324976\t Accuracy:86.142%\n",
      "Epoch : 3 [51200/60000 (85%)]\tLoss: 0.166972\t Accuracy:86.118%\n",
      "Epoch : 3 [57600/60000 (96%)]\tLoss: 0.157313\t Accuracy:86.140%\n",
      "Epoch : 4 [0/60000 (0%)]\tLoss: 0.326028\t Accuracy:87.500%\n",
      "Epoch : 4 [6400/60000 (11%)]\tLoss: 0.321188\t Accuracy:86.101%\n",
      "Epoch : 4 [12800/60000 (21%)]\tLoss: 0.532222\t Accuracy:86.136%\n",
      "Epoch : 4 [19200/60000 (32%)]\tLoss: 0.227647\t Accuracy:86.210%\n",
      "Epoch : 4 [25600/60000 (43%)]\tLoss: 0.272304\t Accuracy:86.415%\n",
      "Epoch : 4 [32000/60000 (53%)]\tLoss: 0.464648\t Accuracy:86.392%\n",
      "Epoch : 4 [38400/60000 (64%)]\tLoss: 0.397416\t Accuracy:86.407%\n",
      "Epoch : 4 [44800/60000 (75%)]\tLoss: 0.283638\t Accuracy:86.498%\n",
      "Epoch : 4 [51200/60000 (85%)]\tLoss: 0.144101\t Accuracy:86.555%\n",
      "Epoch : 4 [57600/60000 (96%)]\tLoss: 0.164851\t Accuracy:86.580%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(SEED)\n",
    "fit(mlp, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.858% \n"
     ]
    }
   ],
   "source": [
    "evaluate(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уменьшать количество самих весов в этот раз мы не будем, поэтому в качестве размера нейронной сети будет использовать буквально количество памяти, которая она занимает."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_size(model):\n",
    "    torch.save(model.state_dict(), \"/tmp/model.p\")\n",
    "    size=os.path.getsize(\"/tmp/model.p\")\n",
    "    os.remove('/tmp/model.p')\n",
    "    return \"{:.3f} KB\".format(size / 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'870.694 KB'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_size(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полученная сеть весит почти мегабайт.\n",
    "\n",
    "Посмотрим на веса, которые используются внутри нашей сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0417,  0.0319,  0.1002,  ...,  0.1496,  0.2197,  0.0276],\n",
       "        [ 0.0319,  0.0167,  0.0228,  ...,  0.0036, -0.0232, -0.0021],\n",
       "        [-0.0136,  0.0015, -0.0036,  ...,  0.0028, -0.0361, -0.0615],\n",
       "        ...,\n",
       "        [ 0.0304, -0.0115, -0.0250,  ..., -0.0063, -0.0719, -0.0729],\n",
       "        [ 0.0178, -0.0027, -0.0122,  ..., -0.0703,  0.0111, -0.0264],\n",
       "        [-0.0081,  0.0118,  0.0321,  ..., -0.0154,  0.0246,  0.0243]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.linear1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (linear1): Linear(in_features=784, out_features=250, bias=True)\n",
       "  (linear2): Linear(in_features=250, out_features=100, bias=True)\n",
       "  (linear3): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем дополнительно, за сколько в среднем она делает предсказания. Для замеров по времени будем использовать один поток, чтобы все сети были в одинаковых условиях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def single_thread():  \n",
    "    num = torch.get_num_threads()\n",
    "    torch.set_num_threads(1)\n",
    "    yield\n",
    "    torch.set_num_threads(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.867% \n",
      "Test accuracy:0.867% \n",
      "Test accuracy:0.867% \n",
      "Test accuracy:0.867% \n",
      "Test accuracy:0.867% \n",
      "Test accuracy:0.867% \n",
      "Test accuracy:0.867% \n",
      "Test accuracy:0.867% \n",
      "Test accuracy:0.867% \n",
      "Test accuracy:0.867% \n",
      "Test accuracy:0.867% \n",
      "2.12 s ± 240 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r10\n",
    "\n",
    "with single_thread():\n",
    "    evaluate(mlp, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Динамическая квантизация\n",
    "\n",
    "Динамическая квантизация - пожалуй самый простой способ квантизации. \n",
    "\n",
    "Все веса из float мы сразу переводим в int, а вот активации мы пересчитываем на лету во время работы сети. Для каждого примера в нейроне мы аккумулируем взвешенную сумму по-честному во float, подбираем для конкретного получившегося числа лучшие параметры квантизации, квантуем и отправляем дальше по сети.\n",
    "\n",
    "Таким образом, из-за этих автоматических квантований во время работы сети сеть все еще может работать медленно.\n",
    "\n",
    "Попробуем применить динамическую квантизацию к нашей модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "qd_mlp = torch.quantization.quantize_dynamic(\n",
    "    mlp, {nn.Linear}, dtype=torch.qint8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (linear1): DynamicQuantizedLinear(in_features=784, out_features=250, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "  (linear2): DynamicQuantizedLinear(in_features=250, out_features=100, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       "  (linear3): DynamicQuantizedLinear(in_features=100, out_features=10, dtype=torch.qint8, qscheme=torch.per_tensor_affine)\n",
       ")"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'222.215 KB'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_size(qd_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что получилось уменьшить размер сети почти в 4 раза. Посмотрим, что случилось с качеством полученной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.864% \n"
     ]
    }
   ],
   "source": [
    "evaluate(qd_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество осталось в точности таким же.\n",
    "\n",
    "Заглянем в то, какие теперь веса используются внутри."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  9,   7,  21,  ...,  32,  47,   6],\n",
       "        [  7,   4,   5,  ...,   1,  -5,   0],\n",
       "        [ -3,   0,  -1,  ...,   1,  -8, -13],\n",
       "        ...,\n",
       "        [  6,  -2,  -5,  ...,  -1, -15, -15],\n",
       "        [  4,  -1,  -3,  ..., -15,   2,  -6],\n",
       "        [ -2,   3,   7,  ...,  -3,   5,   5]], dtype=torch.int8)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qd_mlp.linear1.weight().int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0417,  0.0319,  0.1002,  ...,  0.1496,  0.2197,  0.0276],\n",
       "        [ 0.0319,  0.0167,  0.0228,  ...,  0.0036, -0.0232, -0.0021],\n",
       "        [-0.0136,  0.0015, -0.0036,  ...,  0.0028, -0.0361, -0.0615],\n",
       "        ...,\n",
       "        [ 0.0304, -0.0115, -0.0250,  ..., -0.0063, -0.0719, -0.0729],\n",
       "        [ 0.0178, -0.0027, -0.0122,  ..., -0.0703,  0.0111, -0.0264],\n",
       "        [-0.0081,  0.0118,  0.0321,  ..., -0.0154,  0.0246,  0.0243]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.linear1.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Помотрим, насколько быстро получается делать предсказания квантизированной моделью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.871% \n",
      "Test accuracy:0.871% \n",
      "Test accuracy:0.871% \n",
      "Test accuracy:0.871% \n",
      "Test accuracy:0.871% \n",
      "Test accuracy:0.871% \n",
      "Test accuracy:0.871% \n",
      "Test accuracy:0.871% \n",
      "Test accuracy:0.871% \n",
      "Test accuracy:0.871% \n",
      "Test accuracy:0.871% \n",
      "1.27 s ± 14.5 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r10\n",
    "\n",
    "with single_thread():\n",
    "    evaluate(qd_mlp, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На моем компьютере получился прирост примерно в 10-15%. Таким образом динамическая квантизация - достаточно простой прием, который не дает большого проигрышал по качеству, при этом уменьшает размер сети и ускоряет предсказания.\n",
    "\n",
    "Однако это не единственный подход для квантования. \n",
    "\n",
    "# Статическая квантизация\n",
    "\n",
    "Статическая квантизация позволяет сразу все операции перевести в int, без необходимости дополнительно что-то расчитывать в процессе предсказания.\n",
    "\n",
    "Для того, чтобы при этом качество не сильно пострадало, параметры квантования для разных слоем настраиваются по обучающей выборке.\n",
    "\n",
    "Таким образом для того, чтобы статически квантизировать сеть, необходимо вначале подключить к ней модуль подсчета параметров (Observer), который будет для каждого слоя расчитывать необходимые параметры квантования по обучающей выборке. После этого один раз необходимо всю выборку прогнать через сеть, чтобы эти модули смогли подсчитать нужные параметры. После чего можно фиксировать полученные параметры и итоговую квантизированную сеть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(QuantizedMLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(784,250)\n",
    "        self.linear2 = nn.Linear(250,100)\n",
    "        self.linear3 = nn.Linear(100,10)\n",
    "        # Так как теперь квантизация не происходит динамически, необходимо дополнительно \n",
    "        # руками квантовать входные данные и деквантовать ответ\n",
    "        self.quant = QuantStub()\n",
    "        self.dequant = DeQuantStub()\n",
    "    \n",
    "    def forward(self,X):\n",
    "        # Квантуем входные данные\n",
    "        X = self.quant(X)\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = self.linear3(X)\n",
    "        # Деквантуем ответ\n",
    "        X = self.dequant(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptq_mlp = QuantizedMLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/60000 (0%)]\tLoss: 11.684027\t Accuracy:18.750%\n",
      "Epoch : 0 [6400/60000 (11%)]\tLoss: 0.787137\t Accuracy:69.512%\n",
      "Epoch : 0 [12800/60000 (21%)]\tLoss: 0.993065\t Accuracy:73.862%\n",
      "Epoch : 0 [19200/60000 (32%)]\tLoss: 0.325165\t Accuracy:75.577%\n",
      "Epoch : 0 [25600/60000 (43%)]\tLoss: 0.345738\t Accuracy:76.802%\n",
      "Epoch : 0 [32000/60000 (53%)]\tLoss: 0.604350\t Accuracy:77.563%\n",
      "Epoch : 0 [38400/60000 (64%)]\tLoss: 0.563863\t Accuracy:78.294%\n",
      "Epoch : 0 [44800/60000 (75%)]\tLoss: 0.423202\t Accuracy:78.886%\n",
      "Epoch : 0 [51200/60000 (85%)]\tLoss: 0.235911\t Accuracy:79.384%\n",
      "Epoch : 0 [57600/60000 (96%)]\tLoss: 0.193039\t Accuracy:79.607%\n",
      "Epoch : 1 [0/60000 (0%)]\tLoss: 0.515112\t Accuracy:78.125%\n",
      "Epoch : 1 [6400/60000 (11%)]\tLoss: 0.454121\t Accuracy:83.862%\n",
      "Epoch : 1 [12800/60000 (21%)]\tLoss: 0.842713\t Accuracy:83.713%\n",
      "Epoch : 1 [19200/60000 (32%)]\tLoss: 0.260269\t Accuracy:83.668%\n",
      "Epoch : 1 [25600/60000 (43%)]\tLoss: 0.279924\t Accuracy:83.825%\n",
      "Epoch : 1 [32000/60000 (53%)]\tLoss: 0.636968\t Accuracy:83.791%\n",
      "Epoch : 1 [38400/60000 (64%)]\tLoss: 0.401687\t Accuracy:83.868%\n",
      "Epoch : 1 [44800/60000 (75%)]\tLoss: 0.290916\t Accuracy:83.869%\n",
      "Epoch : 1 [51200/60000 (85%)]\tLoss: 0.217648\t Accuracy:83.967%\n",
      "Epoch : 1 [57600/60000 (96%)]\tLoss: 0.122710\t Accuracy:84.047%\n",
      "Epoch : 2 [0/60000 (0%)]\tLoss: 0.371408\t Accuracy:84.375%\n",
      "Epoch : 2 [6400/60000 (11%)]\tLoss: 0.337995\t Accuracy:84.391%\n",
      "Epoch : 2 [12800/60000 (21%)]\tLoss: 0.921827\t Accuracy:84.554%\n",
      "Epoch : 2 [19200/60000 (32%)]\tLoss: 0.242288\t Accuracy:84.952%\n",
      "Epoch : 2 [25600/60000 (43%)]\tLoss: 0.252544\t Accuracy:84.988%\n",
      "Epoch : 2 [32000/60000 (53%)]\tLoss: 0.527810\t Accuracy:84.946%\n",
      "Epoch : 2 [38400/60000 (64%)]\tLoss: 0.364790\t Accuracy:84.924%\n",
      "Epoch : 2 [44800/60000 (75%)]\tLoss: 0.249926\t Accuracy:85.049%\n",
      "Epoch : 2 [51200/60000 (85%)]\tLoss: 0.201544\t Accuracy:85.070%\n",
      "Epoch : 2 [57600/60000 (96%)]\tLoss: 0.157347\t Accuracy:85.111%\n",
      "Epoch : 3 [0/60000 (0%)]\tLoss: 0.345522\t Accuracy:87.500%\n",
      "Epoch : 3 [6400/60000 (11%)]\tLoss: 0.370528\t Accuracy:85.386%\n",
      "Epoch : 3 [12800/60000 (21%)]\tLoss: 0.718166\t Accuracy:85.614%\n",
      "Epoch : 3 [19200/60000 (32%)]\tLoss: 0.191541\t Accuracy:85.732%\n",
      "Epoch : 3 [25600/60000 (43%)]\tLoss: 0.267915\t Accuracy:85.861%\n",
      "Epoch : 3 [32000/60000 (53%)]\tLoss: 0.502121\t Accuracy:85.839%\n",
      "Epoch : 3 [38400/60000 (64%)]\tLoss: 0.373825\t Accuracy:85.822%\n",
      "Epoch : 3 [44800/60000 (75%)]\tLoss: 0.200227\t Accuracy:85.852%\n",
      "Epoch : 3 [51200/60000 (85%)]\tLoss: 0.142100\t Accuracy:85.983%\n",
      "Epoch : 3 [57600/60000 (96%)]\tLoss: 0.135967\t Accuracy:85.959%\n",
      "Epoch : 4 [0/60000 (0%)]\tLoss: 0.332464\t Accuracy:84.375%\n",
      "Epoch : 4 [6400/60000 (11%)]\tLoss: 0.378113\t Accuracy:87.018%\n",
      "Epoch : 4 [12800/60000 (21%)]\tLoss: 0.603282\t Accuracy:86.448%\n",
      "Epoch : 4 [19200/60000 (32%)]\tLoss: 0.263826\t Accuracy:86.450%\n",
      "Epoch : 4 [25600/60000 (43%)]\tLoss: 0.292952\t Accuracy:86.490%\n",
      "Epoch : 4 [32000/60000 (53%)]\tLoss: 0.419559\t Accuracy:86.445%\n",
      "Epoch : 4 [38400/60000 (64%)]\tLoss: 0.326678\t Accuracy:86.379%\n",
      "Epoch : 4 [44800/60000 (75%)]\tLoss: 0.210361\t Accuracy:86.516%\n",
      "Epoch : 4 [51200/60000 (85%)]\tLoss: 0.142117\t Accuracy:86.546%\n",
      "Epoch : 4 [57600/60000 (96%)]\tLoss: 0.127990\t Accuracy:86.544%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(SEED)\n",
    "fit(ptq_mlp, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.854% \n"
     ]
    }
   ],
   "source": [
    "evaluate(ptq_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для моделей мы также можем указать конфиг квантования,\n",
    "# где в частности может указать библиотеку для работы с квантованными значениями\n",
    "\n",
    "ptq_mlp.qconfig = torch.quantization.get_default_qconfig('fbgemm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PostTrainedQuantizedMLP(\n",
       "  (linear1): Linear(\n",
       "    in_features=784, out_features=250, bias=True\n",
       "    (activation_post_process): HistogramObserver()\n",
       "  )\n",
       "  (linear2): Linear(\n",
       "    in_features=250, out_features=100, bias=True\n",
       "    (activation_post_process): HistogramObserver()\n",
       "  )\n",
       "  (linear3): Linear(\n",
       "    in_features=100, out_features=10, bias=True\n",
       "    (activation_post_process): HistogramObserver()\n",
       "  )\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): HistogramObserver()\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Устанавливаем модули подсчета параметров квантования. По умолчанию исползуется HistogramObserver, то есть\n",
    "# модуль, который рассчтывает параметры на основе гистрограммы распределения значнеий для конкретного слоя\n",
    "torch.quantization.prepare(ptq_mlp, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.863% \n"
     ]
    }
   ],
   "source": [
    "# Прогоняем всю обучающую выборку через сеть. Для этого просто считаем качество на данных обучающей выборки\n",
    "# Само значение нам не интересно, нам важно, чтобы посчитались параметры\n",
    "evaluate(ptq_mlp, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PostTrainedQuantizedMLP(\n",
       "  (linear1): QuantizedLinear(in_features=784, out_features=250, scale=48.7363166809082, zero_point=91, qscheme=torch.per_channel_affine)\n",
       "  (linear2): QuantizedLinear(in_features=250, out_features=100, scale=10.155464172363281, zero_point=80, qscheme=torch.per_channel_affine)\n",
       "  (linear3): QuantizedLinear(in_features=100, out_features=10, scale=1.5792425870895386, zero_point=72, qscheme=torch.per_channel_affine)\n",
       "  (quant): Quantize(scale=tensor([2.0069]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Фиксируем полученные веса и параметры квантизации\n",
    "torch.quantization.convert(ptq_mlp, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно видеть, какие именно параметры (а именно scale и zero_point) подсчитались для каждого слоя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'229.748 KB'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_size(ptq_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-10, -40, -16,  ...,  70,  13,  54],\n",
       "        [-15, -49, -36,  ...,   5,  -8, -19],\n",
       "        [-42, -47,  61,  ...,  23,  68,  57],\n",
       "        ...,\n",
       "        [ 35,  -8, -10,  ..., -51,  25, -72],\n",
       "        [-16,  31,  43,  ...,  41, -75, -47],\n",
       "        [-84,  66,  68,  ..., -35,  67,  86]], dtype=torch.int8)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ptq_mlp.linear1.weight().int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.854% \n"
     ]
    }
   ],
   "source": [
    "evaluate(ptq_mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что модель все еще хорошо сжалась, при этом качество немного упало. \n",
    "\n",
    "Посмотрим, что по скорости выполнения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.863% \n",
      "Test accuracy:0.863% \n",
      "Test accuracy:0.863% \n",
      "Test accuracy:0.863% \n",
      "Test accuracy:0.863% \n",
      "Test accuracy:0.863% \n",
      "Test accuracy:0.863% \n",
      "Test accuracy:0.863% \n",
      "Test accuracy:0.863% \n",
      "Test accuracy:0.863% \n",
      "Test accuracy:0.863% \n",
      "1.33 s ± 22.2 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r10\n",
    "\n",
    "with single_thread():\n",
    "    evaluate(ptq_mlp, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что с текущей моделью статическая квантизация работает не так хорошо - качество немного просело, а значительного прироста по времени не наблюдается.\n",
    "\n",
    "Вместо простых схем квантизации, когда уже обученная модель квантуется, есть и более продвинутые схемы.\n",
    "\n",
    "# Квантизация в процессе обучения\n",
    "\n",
    "Этот метод заключается в том, что квантование происходит на каждом шаге градиентного спуска. Теоретически это должно делать более аккуратными относительно квантованных параметров и тем самым получать качество лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_mlp = QuantizedMLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantized_fit(model, train_loader, epoch_number=5):\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    \n",
    "    # Ничем особенным процесс обучения не отличается\n",
    "    # Добавляем конфигурацию, после чего подготавливаем модель для обучения с квантованием\n",
    "    # Модель внутри себя автоматически будет обновлять веса с учетом квантования\n",
    "    model.qconfig = torch.quantization.get_default_qat_qconfig('fbgemm')\n",
    "    torch.quantization.prepare_qat(model, inplace=True)\n",
    "    \n",
    "    error = nn.CrossEntropyLoss()\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epoch_number):\n",
    "        correct = 0\n",
    "        \n",
    "        for batch_idx, (X_batch, y_batch) in enumerate(train_loader):\n",
    "            var_X_batch = Variable(X_batch).float()\n",
    "            var_y_batch = Variable(y_batch)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            output = model(var_X_batch)\n",
    "            loss = error(output, var_y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            predicted = torch.max(output.data, 1)[1] \n",
    "            correct += (predicted == var_y_batch).sum()\n",
    "            if batch_idx % 200 == 0:\n",
    "                print('Epoch : {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t Accuracy:{:.3f}%'.format(\n",
    "                    epoch, batch_idx*len(X_batch), len(train_loader.dataset), 100.*batch_idx / len(train_loader), loss.data, float(correct*100) / float(BATCH_SIZE*(batch_idx+1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0 [0/60000 (0%)]\tLoss: 19.953337\t Accuracy:3.125%\n",
      "Epoch : 0 [6400/60000 (11%)]\tLoss: 1.015618\t Accuracy:68.470%\n",
      "Epoch : 0 [12800/60000 (21%)]\tLoss: 1.126122\t Accuracy:72.919%\n",
      "Epoch : 0 [19200/60000 (32%)]\tLoss: 0.382234\t Accuracy:74.698%\n",
      "Epoch : 0 [25600/60000 (43%)]\tLoss: 0.263492\t Accuracy:75.964%\n",
      "Epoch : 0 [32000/60000 (53%)]\tLoss: 0.520338\t Accuracy:76.795%\n",
      "Epoch : 0 [38400/60000 (64%)]\tLoss: 0.406278\t Accuracy:77.542%\n",
      "Epoch : 0 [44800/60000 (75%)]\tLoss: 0.436573\t Accuracy:78.083%\n",
      "Epoch : 0 [51200/60000 (85%)]\tLoss: 0.301557\t Accuracy:78.609%\n",
      "Epoch : 0 [57600/60000 (96%)]\tLoss: 0.401963\t Accuracy:79.013%\n",
      "Epoch : 1 [0/60000 (0%)]\tLoss: 0.458184\t Accuracy:87.500%\n",
      "Epoch : 1 [6400/60000 (11%)]\tLoss: 0.491694\t Accuracy:83.411%\n",
      "Epoch : 1 [12800/60000 (21%)]\tLoss: 0.751592\t Accuracy:83.619%\n",
      "Epoch : 1 [19200/60000 (32%)]\tLoss: 0.368394\t Accuracy:83.663%\n",
      "Epoch : 1 [25600/60000 (43%)]\tLoss: 0.291238\t Accuracy:83.770%\n",
      "Epoch : 1 [32000/60000 (53%)]\tLoss: 0.506257\t Accuracy:83.694%\n",
      "Epoch : 1 [38400/60000 (64%)]\tLoss: 0.487764\t Accuracy:83.800%\n",
      "Epoch : 1 [44800/60000 (75%)]\tLoss: 0.255858\t Accuracy:83.808%\n",
      "Epoch : 1 [51200/60000 (85%)]\tLoss: 0.246901\t Accuracy:83.916%\n",
      "Epoch : 1 [57600/60000 (96%)]\tLoss: 0.169946\t Accuracy:83.905%\n",
      "Epoch : 2 [0/60000 (0%)]\tLoss: 0.338304\t Accuracy:87.500%\n",
      "Epoch : 2 [6400/60000 (11%)]\tLoss: 0.423759\t Accuracy:84.670%\n",
      "Epoch : 2 [12800/60000 (21%)]\tLoss: 0.726992\t Accuracy:84.593%\n",
      "Epoch : 2 [19200/60000 (32%)]\tLoss: 0.236238\t Accuracy:84.593%\n",
      "Epoch : 2 [25600/60000 (43%)]\tLoss: 0.293010\t Accuracy:84.648%\n",
      "Epoch : 2 [32000/60000 (53%)]\tLoss: 0.552295\t Accuracy:84.606%\n",
      "Epoch : 2 [38400/60000 (64%)]\tLoss: 0.429808\t Accuracy:84.607%\n",
      "Epoch : 2 [44800/60000 (75%)]\tLoss: 0.463073\t Accuracy:84.741%\n",
      "Epoch : 2 [51200/60000 (85%)]\tLoss: 0.199725\t Accuracy:84.875%\n",
      "Epoch : 2 [57600/60000 (96%)]\tLoss: 0.099700\t Accuracy:84.823%\n",
      "Epoch : 3 [0/60000 (0%)]\tLoss: 0.392204\t Accuracy:84.375%\n",
      "Epoch : 3 [6400/60000 (11%)]\tLoss: 0.415213\t Accuracy:85.230%\n",
      "Epoch : 3 [12800/60000 (21%)]\tLoss: 0.687019\t Accuracy:85.240%\n",
      "Epoch : 3 [19200/60000 (32%)]\tLoss: 0.301354\t Accuracy:85.353%\n",
      "Epoch : 3 [25600/60000 (43%)]\tLoss: 0.321496\t Accuracy:85.385%\n",
      "Epoch : 3 [32000/60000 (53%)]\tLoss: 0.544561\t Accuracy:85.209%\n",
      "Epoch : 3 [38400/60000 (64%)]\tLoss: 0.409837\t Accuracy:85.327%\n",
      "Epoch : 3 [44800/60000 (75%)]\tLoss: 0.290352\t Accuracy:85.397%\n",
      "Epoch : 3 [51200/60000 (85%)]\tLoss: 0.204784\t Accuracy:85.450%\n",
      "Epoch : 3 [57600/60000 (96%)]\tLoss: 0.198320\t Accuracy:85.449%\n",
      "Epoch : 4 [0/60000 (0%)]\tLoss: 0.393940\t Accuracy:87.500%\n",
      "Epoch : 4 [6400/60000 (11%)]\tLoss: 0.427149\t Accuracy:85.557%\n",
      "Epoch : 4 [12800/60000 (21%)]\tLoss: 0.591541\t Accuracy:85.575%\n",
      "Epoch : 4 [19200/60000 (32%)]\tLoss: 0.237643\t Accuracy:85.566%\n",
      "Epoch : 4 [25600/60000 (43%)]\tLoss: 0.280864\t Accuracy:85.803%\n",
      "Epoch : 4 [32000/60000 (53%)]\tLoss: 0.463835\t Accuracy:85.761%\n",
      "Epoch : 4 [38400/60000 (64%)]\tLoss: 0.426036\t Accuracy:85.764%\n",
      "Epoch : 4 [44800/60000 (75%)]\tLoss: 0.251716\t Accuracy:85.834%\n",
      "Epoch : 4 [51200/60000 (85%)]\tLoss: 0.176312\t Accuracy:85.872%\n",
      "Epoch : 4 [57600/60000 (96%)]\tLoss: 0.158091\t Accuracy:85.801%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(SEED)\n",
    "quantized_fit(qa_mlp, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что обучение идет немного дольше чем обычно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PostTrainedQuantizedMLP(\n",
       "  (linear1): QuantizedLinear(in_features=784, out_features=250, scale=35.50273513793945, zero_point=88, qscheme=torch.per_channel_affine)\n",
       "  (linear2): QuantizedLinear(in_features=250, out_features=100, scale=5.187557697296143, zero_point=71, qscheme=torch.per_channel_affine)\n",
       "  (linear3): QuantizedLinear(in_features=100, out_features=10, scale=0.8892423510551453, zero_point=74, qscheme=torch.per_channel_affine)\n",
       "  (quant): Quantize(scale=tensor([2.0079]), zero_point=tensor([0]), dtype=torch.quint8)\n",
       "  (dequant): DeQuantize()\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# После обучения с квантованием, фиксируем квантованные веса и параметры\n",
    "quantized_model = torch.quantization.convert(qa_mlp, inplace=False)\n",
    "quantized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.865% \n"
     ]
    }
   ],
   "source": [
    "evaluate(quantized_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На моем компьютере качество получилось даже чуть выше, чем у оригинальной модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'229.746 KB'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_size(quantized_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  -9,   13,  -17,  ...,  -34,  -34,  -65],\n",
       "        [   9,    4,  -45,  ...,  -13,  -24,   65],\n",
       "        [ -15,  -88,   29,  ...,  -72,   52,   53],\n",
       "        ...,\n",
       "        [  74,   50,  106,  ...,   75,  101,   31],\n",
       "        [ -58,  -68,   57,  ..., -106,  -79,    8],\n",
       "        [ -15,   58,  -44,  ...,  115,   37,  -63]], dtype=torch.int8)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_model.linear1.weight().int_repr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:0.876% \n",
      "Test accuracy:0.876% \n",
      "Test accuracy:0.876% \n",
      "Test accuracy:0.876% \n",
      "Test accuracy:0.876% \n",
      "Test accuracy:0.876% \n",
      "Test accuracy:0.876% \n",
      "Test accuracy:0.876% \n",
      "Test accuracy:0.876% \n",
      "Test accuracy:0.876% \n",
      "Test accuracy:0.876% \n",
      "1.3 s ± 6.6 ms per loop (mean ± std. dev. of 10 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r10\n",
    "\n",
    "with single_thread():\n",
    "    evaluate(quantized_model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По итогу этих экспериментов можно сказать следующее - универсального метода квантизации не существует, в каждом конкретном случае нужно искать свой подход.\n",
    "\n",
    "Однако все схемы показывают стабильное уменьшение размера модели при небольшом изменении метрики качества и ускорении расчета предсказаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
